{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e4d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c235ef5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the maximum length of the input text strings\n",
    "max_len = 120\n",
    "\n",
    "# Define the number of unique characters in the text\n",
    "n_chars = 128\n",
    "\n",
    "# Define the number of neurons in the encoder and decoder layers\n",
    "n_encoder = 128\n",
    "n_decoder = 128\n",
    "\n",
    "# Define the noise probability for the denoising process\n",
    "noise_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02632b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pad_array (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function softmax(x::AbstractVector)\n",
    "    # Compute the exponential of each element in the input vector\n",
    "    exp_x = exp.(x)\n",
    "\n",
    "    # Normalize the exponential values by dividing by the sum of the exponentials\n",
    "    norm_exp_x = exp_x ./ sum(exp_x)\n",
    "\n",
    "    return norm_exp_x\n",
    "end\n",
    "\n",
    "\n",
    "function pad_array(arr::Array, final_length::Int, padval::Char, direction::Symbol)\n",
    "    # Calculate the number of padding elements needed\n",
    "    n_pad = final_length - length(arr)\n",
    "\n",
    "    # Initialize the padded array\n",
    "    padded_arr = copy(arr)\n",
    "\n",
    "    # Add padding elements to the array\n",
    "    if direction == :left\n",
    "        for i in 1:n_pad\n",
    "            pushfirst!(padded_arr, padval)\n",
    "        end\n",
    "    elseif direction == :right\n",
    "        for i in 1:n_pad\n",
    "            push!(padded_arr, padval)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return padded_arr\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66acf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the autoencoder model\n",
    "function autoencoder(max_len, n_chars, n_encoder, n_decoder, noise_prob)\t\n",
    "\t\n",
    "    # Define the encoder and decoder layers\n",
    "    encoder = Chain(\n",
    "        LSTM(n_chars, n_encoder),\n",
    "        Dense(n_encoder, n_encoder)\n",
    "    )\n",
    "\n",
    "    decoder = Chain(\n",
    "        Dense(n_encoder, n_decoder),\n",
    "        LSTM(n_decoder, n_chars),\n",
    "        softmax\n",
    "    )\n",
    "\n",
    "    # Define the autoencoder model by stacking the encoder and decoder layers\n",
    "    model = Chain(encoder, decoder)\n",
    "\n",
    "    # Define the loss function and optimization algorithm\n",
    "    loss(x, y) = crossentropy(model(x), y)\n",
    "    opt = ADAM()\n",
    "\n",
    "    # Define the function for training the autoencoder\n",
    "    ps = Flux.params(model)\n",
    "    function train_autoencoder(data, epochs)\n",
    "\t\tfor epoch in 1:2\n",
    "\t\t   Flux.train!(loss,ps, zip(data), opt)\n",
    "\t\tend\t\t\t\t\n",
    "    end\n",
    "\n",
    "    # Define the function for denoising the input text\n",
    "    function denoise_text(text)\n",
    "        # Convert the input text to a one-hot encoded tensor\n",
    "        text_oh = onehotbatch(text, 1:n_chars)\n",
    "\n",
    "        # Add noise to the input tensor with probability `noise_prob`\n",
    "        text_noisy = map(x -> x .* (rand(size(x)) .> noise_prob), text_oh)\n",
    "\n",
    "        # Denoise the input text by passing it through the autoencoder model\n",
    "        text_denoised = model(text_noisy)\n",
    "\n",
    "        # Convert the denoised tensor back to text\n",
    "        return String(argmax(text_denoised, dims=2))\n",
    "    end\n",
    "\n",
    "    return model, train_autoencoder, denoise_text\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1af837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128-element Vector{Char}:\n",
       " 'T': ASCII/Unicode U+0054 (category Lu: Letter, uppercase)\n",
       " 'h': ASCII/Unicode U+0068 (category Ll: Letter, lowercase)\n",
       " 'i': ASCII/Unicode U+0069 (category Ll: Letter, lowercase)\n",
       " 's': ASCII/Unicode U+0073 (category Ll: Letter, lowercase)\n",
       " ' ': ASCII/Unicode U+0020 (category Zs: Separator, space)\n",
       " 'i': ASCII/Unicode U+0069 (category Ll: Letter, lowercase)\n",
       " 's': ASCII/Unicode U+0073 (category Ll: Letter, lowercase)\n",
       " ' ': ASCII/Unicode U+0020 (category Zs: Separator, space)\n",
       " 'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\n",
       " ' ': ASCII/Unicode U+0020 (category Zs: Separator, space)\n",
       " 't': ASCII/Unicode U+0074 (category Ll: Letter, lowercase)\n",
       " 'e': ASCII/Unicode U+0065 (category Ll: Letter, lowercase)\n",
       " 's': ASCII/Unicode U+0073 (category Ll: Letter, lowercase)\n",
       " â‹®\n",
       " '0': ASCII/Unicode U+0030 (category Nd: Number, decimal digit)\n",
       " '0': ASCII/Unicode U+0030 (category Nd: Number, decimal digit)\n",
       " '0': ASCII/Unicode U+0030 (category Nd: Number, decimal digit)\n",
       " '0': ASCII/Unicode U+0030 (category Nd: Number, decimal digit)\n",
       " '0': ASCII/Unicode U+0030 (category Nd: Number, decimal digit)\n",
       " '0': ASCII/Unicode U+0030 (category Nd: Number, decimal digit)\n",
       " '0': ASCII/Unicode U+0030 (category Nd: Number, decimal digit)\n",
       " '0': ASCII/Unicode U+0030 (category Nd: Number, decimal digit)\n",
       " '0': ASCII/Unicode U+0030 (category Nd: Number, decimal digit)\n",
       " '0': ASCII/Unicode U+0030 (category Nd: Number, decimal digit)\n",
       " '0': ASCII/Unicode U+0030 (category Nd: Number, decimal digit)\n",
       " '0': ASCII/Unicode U+0030 (category Nd: Number, decimal digit)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a test text string\n",
    "test_text = \"This is a test text string to be denoised by the autoencoder.\"\n",
    "\n",
    "# Pad the test text string to the maximum length\n",
    "test_arr = collect(test_text)\n",
    "test_text_padded = pad_array(test_arr,n_chars,'0',:right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88b716b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Chain(Chain(Recur(LSTMCell(128 => 128)), Dense(128 => 128)), Chain(Dense(128 => 128), Recur(LSTMCell(128 => 128)), softmax)), train_autoencoder, denoise_text)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the autoencoder model\n",
    "model, train_autoencoder, denoise_text = \n",
    "\tautoencoder(max_len, n_chars, n_encoder, n_decoder, noise_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c9fc344",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching (::var\"#loss#2\"{Chain{Tuple{Chain{Tuple{Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, typeof(softmax)}}}}})(::Char)\n\u001b[0mClosest candidates are:\n\u001b[0m  (::var\"#loss#2\")(::Any, \u001b[91m::Any\u001b[39m) at In[4]:20",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching (::var\"#loss#2\"{Chain{Tuple{Chain{Tuple{Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, typeof(softmax)}}}}})(::Char)\n\u001b[0mClosest candidates are:\n\u001b[0m  (::var\"#loss#2\")(::Any, \u001b[91m::Any\u001b[39m) at In[4]:20",
      "",
      "Stacktrace:",
      "  [1] macro expansion",
      "    @ ~/.julia/packages/Zygote/SmJK6/src/compiler/interface2.jl:0 [inlined]",
      "  [2] _pullback(ctx::Zygote.Context{true}, f::var\"#loss#2\"{Chain{Tuple{Chain{Tuple{Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, typeof(softmax)}}}}}, args::Char)",
      "    @ Zygote ~/.julia/packages/Zygote/SmJK6/src/compiler/interface2.jl:9",
      "  [3] _apply(::Function, ::Vararg{Any})",
      "    @ Core ./boot.jl:816",
      "  [4] adjoint",
      "    @ ~/.julia/packages/Zygote/SmJK6/src/lib/lib.jl:203 [inlined]",
      "  [5] _pullback",
      "    @ ~/.julia/packages/ZygoteRules/AIbCs/src/adjoint.jl:65 [inlined]",
      "  [6] _pullback",
      "    @ ~/.julia/packages/Flux/kq9Et/src/optimise/train.jl:143 [inlined]",
      "  [7] _pullback(::Zygote.Context{true}, ::Flux.Optimise.var\"#37#40\"{var\"#loss#2\"{Chain{Tuple{Chain{Tuple{Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, typeof(softmax)}}}}}, Tuple{Char}})",
      "    @ Zygote ~/.julia/packages/Zygote/SmJK6/src/compiler/interface2.jl:0",
      "  [8] pullback(f::Function, ps::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})",
      "    @ Zygote ~/.julia/packages/Zygote/SmJK6/src/compiler/interface.jl:384",
      "  [9] withgradient(f::Function, args::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})",
      "    @ Zygote ~/.julia/packages/Zygote/SmJK6/src/compiler/interface.jl:132",
      " [10] macro expansion",
      "    @ ~/.julia/packages/Flux/kq9Et/src/optimise/train.jl:142 [inlined]",
      " [11] macro expansion",
      "    @ ~/.julia/packages/ProgressLogging/6KXlp/src/ProgressLogging.jl:328 [inlined]",
      " [12] train!(loss::Function, ps::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}}, data::Base.Iterators.Zip{Tuple{Vector{Char}}}, opt::Adam; cb::Flux.Optimise.var\"#38#41\")",
      "    @ Flux.Optimise ~/.julia/packages/Flux/kq9Et/src/optimise/train.jl:140",
      " [13] train!",
      "    @ ~/.julia/packages/Flux/kq9Et/src/optimise/train.jl:136 [inlined]",
      " [14] (::var\"#train_autoencoder#3\"{Zygote.Params{Zygote.Buffer{Any, Vector{Any}}}, Adam, var\"#loss#2\"{Chain{Tuple{Chain{Tuple{Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, typeof(softmax)}}}}}})(data::Vector{Char}, epochs::Int64)",
      "    @ Main ./In[4]:27",
      " [15] top-level scope",
      "    @ In[8]:2"
     ]
    }
   ],
   "source": [
    "# Train the autoencoder model on the test text\n",
    "train_autoencoder(test_text_padded, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca0a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
